{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical Asset Pricing - PS4\n",
    "\n",
    "Maximilian Huber\n",
    "\n",
    "## Task 1\n",
    "Let me load the data into an array of DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Query, Plots, Optim; gr();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I load the data, drop rows with a missing value and split the sample in to the two managers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (CSV.read(\"./Data/PS4data.csv\", delim=',', nullable=true,\n",
    "        types=[String, String, Int64, Int64, Int64, Float64, Float64, Int64, Float64, Float64, Float64, Float64, Int64, Float64, Float64, Float64, Float64]))\n",
    "dropmissing!(data)\n",
    "\n",
    "for col in names(data)\n",
    "   data[col] = Missings.coalesce.(data[col], 0)\n",
    "end\n",
    "\n",
    "DFA = data[data[:mgrno] .== 23000, 4:end]\n",
    "VAN = data[data[:mgrno] .== 90457, 4:end];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries for (a)\n",
    "Let me try to understand the data set. Since $\\sum_{n=0}^N w_i(n) = 1$, $\\sum_{n=1}^N w_i(n) = 1 - w_i(0)$, and hence $w_i(0) \\Big(1 + \\frac{\\sum_{n=1}^N w_i(n)}{w_i(0)}\\Big) = 1$. Therefore, cash holdings (or whatever the outside asset is) are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10284923721109153"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_DFA0 = 1 / (1 + sum(DFA[:rweight]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1383314470907214"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_VAN0 = 1 / (1 + sum(VAN[:rweight]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFA[:weight] = DFA[:rweight] * w_DFA0\n",
    "VAN[:weight] = VAN[:rweight] * w_VAN0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does one fund invest in some assets that the other fund does not? I.e. $\\mathcal{N}_{VAN} = \\mathcal{N}_{DFA}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Int64,1}:\n",
       " -229\n",
       "  -78"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[length(DFA[:permno]), length(VAN[:permno])] .- length(union(DFA[:permno], VAN[:permno]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, and neither is a superset of the other!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I assume that I can infere $\\mathcal{N}_{i}$ just by looking at the current portfolio. This would lead to equal estimates in (b) and (f), I think."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4535664834349477"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_share(W) = 1/2 * sum(abs.(W[:weight] .- exp.(W[:LNme]) ./ sum(exp.(W[:LNme]))))\n",
    "\n",
    "active_share(DFA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09184197495623975"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_share(VAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DFA is much more active than Vanguard! The latter offers more products that track market-cap-weighted indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) - (e)\n",
    "I loosely follow the Bruce Hansen's [textbook](https://www.ssc.wisc.edu/~bhansen/econometrics/Econometrics.pdf) for the GMM estimation, except I alter some notation a bit. GMM solves:\n",
    "$$\\underset{\\theta}{\\min}Q_n(\\theta)$$\n",
    "optimizes $Q(\\theta) = \\frac{1}{2} \\, g_n(\\theta)' \\, \\mathcal{W} \\, g_n(\\theta)$ where $g_n(\\theta) = \\frac{1}{n}\\sum_{t=1}^n g(w_t;\\theta)$\n",
    "\n",
    "In the just-identified IV-GMM case $g(w;\\theta)=\\Big(w_{lhs} - w_{reg}'\\cdot\\theta\\Big)\\cdot w_{iv}\\in\\mathbb{R}^k$, where $k$ is the number of regressors and also instrumental variables.\n",
    "\n",
    "In my application the difference between regressors and instruments is just swapping out $LNme$ with $IVme$.\n",
    "\n",
    "Since I have to do an non-linear GMM estimation in (f) I do not follow Hansen's simple derivations of the GMM in linear models, but set up the optimizition problem generically, using a barrier method optimizer with L-BFGS in the inner problem and auto-differentiation.\n",
    "\n",
    "The main issue is the correct covariance estimation for the estimated $\\hat\\theta$.\n",
    "\n",
    "$$\\hat\\Omega=\\frac{1}{n}\\sum_t g(w_t;\\tilde\\theta)\\,g(w_t;\\tilde\\theta)'$$\n",
    "\n",
    "No matter whether the constraint is binding or not, the efficient weighting matrix is $\\mathcal{W} = \\hat\\Omega^{-1}$, see BH chapter 12.14 \"Restricted GMM\".\n",
    "\n",
    "If $\\hat \\theta$ is unconstrained, then $\\hat V_\\theta = \\Big(\\hat G'\\hat\\Omega^{-1}\\hat G\\Big)^{-1}$, where $\\hat G = \\frac{1}{n}\\sum_t \\frac{\\partial g}{\\partial\\theta'} (w_t;\\hat \\theta)$.\n",
    "\n",
    "But $\\hat \\theta$ is fulfilling the restriction with equality, I need to correct for that: $\\hat V_{\\theta,constr} = \\hat V_\\theta - \\hat V_\\theta R \\Big(R'\\hat V_\\theta R\\Big)^{-1} R' \\hat V_\\theta$, where R is Jacobian of the restriction $r(\\theta) = c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ωhat (generic function with 1 method)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#operates on a single observation, w[1] = lhs, w[2:k] = regressors\n",
    "function g(w, θ)\n",
    "    k = ceil(Int64, length(w)/2)\n",
    "    (w[1] - w[2:k]' * θ) * w[k+1:end]\n",
    "end\n",
    "\n",
    "function gn(w, θ)\n",
    "    avg_g = zeros(length(θ))\n",
    "    for t in 1:size(w, 1)\n",
    "        avg_g += g(w[t, :], θ)\n",
    "    end\n",
    "    \n",
    "    return avg_g/size(w, 1)\n",
    "end\n",
    "\n",
    "function gn_wrapper(W)\n",
    "    N = size(W, 1)\n",
    "    w = hcat(W[:LNrweight], \n",
    "        Matrix(W[[:LNme, :LNbe, :profit, :Gat, :divA_be, :beta]]), ones(N),\n",
    "        Matrix(W[[:IVme, :LNbe, :profit, :Gat, :divA_be, :beta]]), ones(N))\n",
    "    return θ -> gn(w, θ)\n",
    "end\n",
    "\n",
    "function Qn(θ, gn_wrapped)\n",
    "    1/2 * (gn_wrapped(θ)' * gn_wrapped(θ))[1]\n",
    "end\n",
    "\n",
    "function Qn(θ, gn_wrapped, Ω)\n",
    "    1/2 * (gn_wrapped(θ)' * Ω * gn_wrapped(θ))[1]\n",
    "end\n",
    "\n",
    "function Ωhat(W, θ)\n",
    "    N = size(W, 1)\n",
    "    w = hcat(W[:LNrweight], \n",
    "        \n",
    "        Matrix(W[[:LNme, :LNbe, :profit, :Gat, :divA_be, :beta]]), ones(N),\n",
    "        Matrix(W[[:IVme, :LNbe, :profit, :Gat, :divA_be, :beta]]), ones(N))\n",
    "    \n",
    "    result = zeros(Float64, length(θ), length(θ))\n",
    "    for i in 1:N\n",
    "        result .+= g(w[i,:], θ) * g(w[i,:], θ)'\n",
    "    end\n",
    "    return result/N\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eff_IV_GMM (generic function with 1 method)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function eff_IV_GMM(W)\n",
    "    #first stage\n",
    "    initial_θ = 0.5 * ones(7)\n",
    "    lower = -Inf * ones(length(initial_θ))\n",
    "    upper = vcat(1, Inf * ones(length(initial_θ) - 1))\n",
    "    \n",
    "    gn_wrapped = gn_wrapper(W)\n",
    "    obj = OnceDifferentiable(θ -> Qn(θ, gn_wrapped), initial_θ; autodiff = :forward)\n",
    "    first_θ = Optim.minimizer(optimize(obj, initial_θ, lower, upper, Fminbox{LBFGS}()))\n",
    "\n",
    "    #second stage\n",
    "    obj = OnceDifferentiable(θ -> Qn(θ, gn_wrapped, Ωhat(W, first_θ)), first_θ; autodiff = :forward)\n",
    "    obj.df(first_θ, first_θ)\n",
    "    second_θ = Optim.minimizer(optimize(obj, first_θ, lower, upper, Fminbox{LBFGS}()))\n",
    "    \n",
    "    #asymptotic variance estimation\n",
    "    G = ForwardDiff.jacobian(gn_wrapped, second_θ)\n",
    "    Vhat = (G' * Ωhat(W, second_θ)^(-1) * G)^(-1)\n",
    "\n",
    "    #correction in case of binding constraint\n",
    "    if second_θ[1] ≈ 1\n",
    "        R = vcat(1, zeros(length(initial_θ) - 1))\n",
    "        Vhat = Vhat - Vhat*R * (R'*Vhat*R)^(-1) * R' * Vhat\n",
    "    end\n",
    "    \n",
    "    #return point estimates and sample std errors\n",
    "    return [second_θ, Vhat/size(W, 1)] \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>coefficient</th><th>VAN_θ</th><th>VAN_θ_stderr</th><th>DFA_θ</th><th>DFA_θ_stderr</th></tr></thead><tbody><tr><th>1</th><td>LNme</td><td>1.0</td><td>0.0</td><td>0.459876</td><td>0.06725</td></tr><tr><th>2</th><td>LNbe</td><td>0.15846</td><td>0.016577</td><td>0.293579</td><td>0.0643384</td></tr><tr><th>3</th><td>profit</td><td>-1.11222</td><td>0.0996191</td><td>1.47946</td><td>0.152318</td></tr><tr><th>4</th><td>Gat</td><td>0.89921</td><td>0.118206</td><td>-1.0244</td><td>0.197911</td></tr><tr><th>5</th><td>divA_be</td><td>32.2135</td><td>1.76347</td><td>-3.15368</td><td>0.783229</td></tr><tr><th>6</th><td>beta</td><td>0.43946</td><td>0.0404025</td><td>0.360101</td><td>0.0503239</td></tr><tr><th>7</th><td>constant</td><td>-17.5322</td><td>0.0990471</td><td>-12.5887</td><td>0.124217</td></tr></tbody></table>"
      ],
      "text/plain": [
       "7×5 DataFrames.DataFrame\n",
       "│ Row │ coefficient │ VAN_θ    │ VAN_θ_stderr │ DFA_θ    │ DFA_θ_stderr │\n",
       "├─────┼─────────────┼──────────┼──────────────┼──────────┼──────────────┤\n",
       "│ 1   │ LNme        │ 1.0      │ 0.0          │ 0.459876 │ 0.06725      │\n",
       "│ 2   │ LNbe        │ 0.15846  │ 0.016577     │ 0.293579 │ 0.0643384    │\n",
       "│ 3   │ profit      │ -1.11222 │ 0.0996191    │ 1.47946  │ 0.152318     │\n",
       "│ 4   │ Gat         │ 0.89921  │ 0.118206     │ -1.0244  │ 0.197911     │\n",
       "│ 5   │ divA_be     │ 32.2135  │ 1.76347      │ -3.15368 │ 0.783229     │\n",
       "│ 6   │ beta        │ 0.43946  │ 0.0404025    │ 0.360101 │ 0.0503239    │\n",
       "│ 7   │ constant    │ -17.5322 │ 0.0990471    │ -12.5887 │ 0.124217     │"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = DataFrame(); table[:coefficient] = [:LNme, :LNbe, :profit, :Gat, :divA_be, :beta, :constant]; \n",
    "result = eff_IV_GMM(VAN)\n",
    "table[:VAN_θ] = result[1]; table[:VAN_θ_stderr] = sqrt.(diag(result[2]))\n",
    "result = eff_IV_GMM(DFA)\n",
    "table[:DFA_θ] = result[1]; table[:DFA_θ_stderr] = sqrt.(diag(result[2]))\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Vanguard</b> is not exactly an index fund, but the $1.0$ coefficient on market equity point into this direction. Other factors are not very important. Vanguard does not seem inelastic.\n",
    "\n",
    "<b>DFA</b> has a much lower coefficient on market equity, but coefficients on profit, Gat, divA, and beta are much higher in magnitude. DFA does not seem like an index fund, but also not like a value fund, because then the coefficients on market equity and book equity should be the same value with opposing signs. It has a less elastic demand than Vanguard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function g(w, θ)\n",
    "    k = ceil(Int64, length(w)/2)\n",
    "    \n",
    "    ε = exp(w[1]) / exp(w[2:k]' * θ)\n",
    "    ε * w[k+1:end]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21.237945 seconds (175.10 M allocations: 9.285 GiB, 4.84% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Results of Optimization Algorithm\n",
       " * Algorithm: Fminbox with L-BFGS\n",
       " * Starting Point: [0.5,0.5,0.5,0.5,0.5,0.5,0.5]\n",
       " * Minimizer: [-19.579462530534947,62.73979273458934, ...]\n",
       " * Minimum: 3.658540e-62\n",
       " * Iterations: 1\n",
       " * Convergence: true\n",
       "   * |x - x'| ≤ 1.0e-32: false \n",
       "     |x - x'| = 1.27e+02 \n",
       "   * |f(x) - f(x')| ≤ 1.0e-32 |f(x)|: false\n",
       "     |f(x) - f(x')| = 7.23e+50 |f(x)|\n",
       "   * |g(x)| ≤ 1.0e-14: true \n",
       "     |g(x)| = 1.76e-17 \n",
       "   * Stopped by an increasing objective: false\n",
       "   * Reached Maximum Number of Iterations: false\n",
       " * Objective Calls: 249\n",
       " * Gradient Calls: 249"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = DFA\n",
    "#first stage\n",
    "    initial_θ = 0.5 * ones(7)\n",
    "    lower = -Inf * ones(length(initial_θ))\n",
    "    upper = vcat(1, Inf * ones(length(initial_θ) - 1))\n",
    "    \n",
    "    gn_wrapped = gn_wrapper(W)\n",
    "    obj = OnceDifferentiable(θ -> -Qn(θ, gn_wrapped), initial_θ; autodiff = :forward)\n",
    "@time    results = optimize(obj, initial_θ, lower, upper, Fminbox{LBFGS}(), \n",
    "    optimizer_o = Optim.Options(g_tol=1e-14), g_tol=1e-14)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mRecompiling stale cache file C:\\Users\\Max\\AppData\\Local\\JuliaPro-0.6.2.1\\pkgs-0.6.2.1\\lib\\v0.6\\Ipopt.ji for module Ipopt.\n",
      "\u001b[39m"
     ]
    }
   ],
   "source": [
    "using JuMP, Ipopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ θ_{1} \\leq 1 $$"
      ],
      "text/plain": [
       "θ[1] <= 1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Model(solver=IpoptSolver())\n",
    "@variable(m, θ[1:7])\n",
    "@constraint(m, θ[1] <= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "myf(a,b,c,d,e,f,g) = -Qn([a,b,c,d,e,f,g], gn_wrapped)\n",
    "JuMP.register(m, :myf, 7, myf, autodiff=true)\n",
    "\n",
    "@NLobjective(m, Min, myf(θ[1], θ[2], θ[3], θ[4], θ[5], θ[6], θ[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solve(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
