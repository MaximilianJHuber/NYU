{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical IO PS 2\n",
    "Maximilian Huber\n",
    "\n",
    "This code is stored at: https://github.com/MaximilianJHuber/NYU/blob/master/EmpIO/PS2.ipynb.\n",
    "The notation follows along the lines of Berry, Levinsohn, Pakes (1995): http://www.tcd.ie/Economics/staff/ppwalsh/papers/BLP.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using Optim.optimize in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "using DataFrames\n",
    "using GLM\n",
    "using Optim\n",
    "using LaTeXStrings\n",
    "\n",
    "data = readtable(\"data_ps2.txt\", header=false, separator=',')\n",
    "rename!(data, names(data), [:car, :year, :firm, :price, :quantity, :weight, :hp, :ac, :nest3, :nest4]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A car can change characteristics over the years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>car</th><th>year</th><th>firm</th><th>price</th><th>quantity</th><th>weight</th><th>hp</th><th>ac</th><th>nest3</th><th>nest4</th></tr></thead><tbody><tr><th>1</th><td>91</td><td>1990</td><td>19</td><td>5995</td><td>52409.0</td><td>1620</td><td>55</td><td>0</td><td>1</td><td>1</td></tr><tr><th>2</th><td>91</td><td>1991</td><td>19</td><td>6807</td><td>55056.0</td><td>1620</td><td>55</td><td>1</td><td>1</td><td>1</td></tr><tr><th>3</th><td>91</td><td>1992</td><td>19</td><td>8219</td><td>66046.0</td><td>1576</td><td>55</td><td>1</td><td>1</td><td>1</td></tr></tbody></table>"
      ],
      "text/plain": [
       "3×10 DataFrames.DataFrame\n",
       "│ Row │ car │ year │ firm │ price │ quantity │ weight │ hp │ ac │ nest3 │\n",
       "├─────┼─────┼──────┼──────┼───────┼──────────┼────────┼────┼────┼───────┤\n",
       "│ 1   │ 91  │ 1990 │ 19   │ 5995  │ 52409.0  │ 1620   │ 55 │ 0  │ 1     │\n",
       "│ 2   │ 91  │ 1991 │ 19   │ 6807  │ 55056.0  │ 1620   │ 55 │ 1  │ 1     │\n",
       "│ 3   │ 91  │ 1992 │ 19   │ 8219  │ 66046.0  │ 1576   │ 55 │ 1  │ 1     │\n",
       "\n",
       "│ Row │ nest4 │\n",
       "├─────┼───────┤\n",
       "│ 1   │ 1     │\n",
       "│ 2   │ 1     │\n",
       "│ 3   │ 1     │"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[:car] .== 91, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, one can argue that product and time dimensions collapse into one. But for the time being lets treat good $j$ to be a _car_, time $t$ to be a _year_ and characteristics $x$ to be _weight_, _horse power_ and _air conditioning_ and finally the price $p$ be _price_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: Logit\n",
    "\n",
    "This part follows BLP (1995) section 6.1.\n",
    "\n",
    "### 1\n",
    "Agent $i$ derives utility from good $j$ at time $t$ in the following manner:\n",
    "$$u_{ijt} = \\delta_{jt}^* + \\epsilon_{ijt} \\quad \\text{and} \\quad \\delta_{jt}^* = x'_{jt}\\beta_t - \\alpha_t p_{jt}+ \\xi_{jt} \\quad \\forall t \\in T$$\n",
    "where $\\epsilon_{ijt}$ is an i.i.d. extrem value.\n",
    "This logit model has market shares:\n",
    "$$s_{jt} = \\frac{e^{\\delta_{jt}^*}}{1 + \\sum_{k=1}^J e^{\\delta_{kt}^*}}$$\n",
    "Taking logs yields:\n",
    "$$\\log s_{jt} - \\log s_{0t} = \\delta_{jt}^* = x'_{jt}\\beta_t - \\alpha_t p_{jt} + \\xi_{jt} $$\n",
    "where $\\xi_{jt}$ is the unobservable good and time specific utility.\n",
    "\n",
    "This equation will be estimated year-by-year.\n",
    "\n",
    "### 2 \n",
    "If I had chosen instead to pool the years the derivation would not change, but panel logit relies on the time-independence of $\\xi_{jt}$, which is very implausible.\n",
    "\n",
    "### 3 \n",
    "Now I estimate the model with GMM using the BLP instrument for $p$:\n",
    "\n",
    "#### Data Preparation\n",
    "Market shares are calculated with an assumed market size of 100 million:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data[:share] = data[:quantity] / 1e8;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instruments for the price are constructed by looking at the good's competitors, as defined by the goods produced by other firms, avaiable in the same year. I average of the characteristics of those competing goods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I normalize weight, horse power and price AFTER creating the instruments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "firm_mean_characteristic (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function competitor_mean_characteristic(good, char::Symbol)\n",
    "    mean(data[(data[:firm] .!= good[:firm]) .* (data[:year] .== good[:year]), char]) #same year, different firm\n",
    "end\n",
    "\n",
    "function firm_mean_characteristic(good, char::Symbol)\n",
    "    mean(data[(data[:firm] .== good[:firm]) .* (data[:year] .== good[:year]) .* \n",
    "            (data[:car] .!= good[:car]), char]) #same year, same firm, different product\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:comp_weight] = [competitor_mean_characteristic(good, :weight) for good in eachrow(data)]\n",
    "data[:comp_hp]     = [competitor_mean_characteristic(good, :hp) for good in eachrow(data)]\n",
    "data[:comp_ac]     = [competitor_mean_characteristic(good, :ac) for good in eachrow(data)]\n",
    "\n",
    "data[:firm_weight] = [firm_mean_characteristic(good, :weight) for good in eachrow(data)]\n",
    "data[:firm_hp]     = [firm_mean_characteristic(good, :hp) for good in eachrow(data)]\n",
    "data[:firm_ac]     = [firm_mean_characteristic(good, :ac) for good in eachrow(data)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some firms only have one product, so that there are some NaN created. These are replaced with zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[isnan.(data[:firm_weight]),:firm_weight] = 0.0\n",
    "data[isnan.(data[:firm_hp]),:firm_hp] = 0.0\n",
    "data[isnan.(data[:firm_ac]),:firm_ac] = 0.0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanprice = mean(data[:price])\n",
    "\n",
    "data[:weight] = data[:weight] / mean(data[:weight])\n",
    "data[:hp]     = data[:hp] / mean(data[:hp])\n",
    "data[:price]  = data[:price] / mean(data[:price]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the left hand side of the model is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:LHS] = zeros(size(data)[1])\n",
    "\n",
    "for y in [1990, 1991, 1992]\n",
    "    data[data[:year] .== y, :LHS] = \n",
    "        log(data[data[:year] .== y, :share]) - log(1 - sum(data[data[:year] .== y, :share]))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>car</th><th>year</th><th>firm</th><th>price</th><th>quantity</th><th>weight</th><th>hp</th><th>ac</th><th>nest3</th><th>nest4</th><th>share</th><th>comp_weight</th><th>comp_hp</th><th>comp_ac</th><th>firm_weight</th><th>firm_hp</th><th>firm_ac</th><th>LHS</th></tr></thead><tbody><tr><th>1</th><td>91</td><td>1990</td><td>19</td><td>0.2970233932704021</td><td>52409.0</td><td>0.5559956020578457</td><td>0.4081228050300215</td><td>0</td><td>1</td><td>1</td><td>0.00052409</td><td>2884.78125</td><td>131.59375</td><td>0.4270833333333333</td><td>3071.029411764706</td><td>141.52941176470588</td><td>0.5588235294117647</td><td>-7.462877776838659</td></tr><tr><th>2</th><td>35</td><td>1990</td><td>7</td><td>0.4307953969117842</td><td>17122.0</td><td>0.7619198991163071</td><td>0.7420414636909483</td><td>0</td><td>2</td><td>2</td><td>0.00017122</td><td>2936.9590163934427</td><td>134.9262295081967</td><td>0.45081967213114754</td><td>2805.625</td><td>117.375</td><td>0.625</td><td>-8.581591922822227</td></tr><tr><th>3</th><td>61</td><td>1990</td><td>16</td><td>0.43822717489186097</td><td>65590.0</td><td>0.8974867280131275</td><td>0.6900985612325818</td><td>0</td><td>1</td><td>1</td><td>0.0006559</td><td>2934.913043478261</td><td>136.40869565217392</td><td>0.5043478260869565</td><td>2856.266666666667</td><td>114.66666666666667</td><td>0.13333333333333333</td><td>-7.238532863836876</td></tr><tr><th>4</th><td>52</td><td>1990</td><td>10</td><td>0.5360293731096715</td><td>49877.0</td><td>0.8662548762925941</td><td>0.6826781465956724</td><td>0</td><td>1</td><td>1</td><td>0.00049877</td><td>2938.9133858267714</td><td>135.03149606299212</td><td>0.47244094488188976</td><td>2402.6666666666665</td><td>86.33333333333333</td><td>0.0</td><td>-7.51239613448586</td></tr><tr><th>5</th><td>26</td><td>1990</td><td>4</td><td>0.6837235741670641</td><td>35944.0</td><td>0.7488780269692712</td><td>0.8607680978814999</td><td>0</td><td>2</td><td>3</td><td>0.00035944</td><td>2935.7698412698414</td><td>134.31746031746033</td><td>0.46825396825396826</td><td>2721.25</td><td>115.0</td><td>0.25</td><td>-7.839993937374661</td></tr><tr><th>6</th><td>54</td><td>1990</td><td>11</td><td>0.8420204451426995</td><td>4640.0</td><td>0.9376419659395274</td><td>0.9498130735244137</td><td>1</td><td>2</td><td>2</td><td>4.64e-5</td><td>2924.186046511628</td><td>133.50387596899225</td><td>0.4496124031007752</td><td>3022.0</td><td>150.0</td><td>1.0</td><td>-9.887241742904356</td></tr></tbody></table>"
      ],
      "text/plain": [
       "6×18 DataFrames.DataFrame\n",
       "│ Row │ car │ year │ firm │ price    │ quantity │ weight   │ hp       │ ac │\n",
       "├─────┼─────┼──────┼──────┼──────────┼──────────┼──────────┼──────────┼────┤\n",
       "│ 1   │ 91  │ 1990 │ 19   │ 0.297023 │ 52409.0  │ 0.555996 │ 0.408123 │ 0  │\n",
       "│ 2   │ 35  │ 1990 │ 7    │ 0.430795 │ 17122.0  │ 0.76192  │ 0.742041 │ 0  │\n",
       "│ 3   │ 61  │ 1990 │ 16   │ 0.438227 │ 65590.0  │ 0.897487 │ 0.690099 │ 0  │\n",
       "│ 4   │ 52  │ 1990 │ 10   │ 0.536029 │ 49877.0  │ 0.866255 │ 0.682678 │ 0  │\n",
       "│ 5   │ 26  │ 1990 │ 4    │ 0.683724 │ 35944.0  │ 0.748878 │ 0.860768 │ 0  │\n",
       "│ 6   │ 54  │ 1990 │ 11   │ 0.84202  │ 4640.0   │ 0.937642 │ 0.949813 │ 1  │\n",
       "\n",
       "│ Row │ nest3 │ nest4 │ share      │ comp_weight │ comp_hp │ comp_ac  │\n",
       "├─────┼───────┼───────┼────────────┼─────────────┼─────────┼──────────┤\n",
       "│ 1   │ 1     │ 1     │ 0.00052409 │ 2884.78     │ 131.594 │ 0.427083 │\n",
       "│ 2   │ 2     │ 2     │ 0.00017122 │ 2936.96     │ 134.926 │ 0.45082  │\n",
       "│ 3   │ 1     │ 1     │ 0.0006559  │ 2934.91     │ 136.409 │ 0.504348 │\n",
       "│ 4   │ 1     │ 1     │ 0.00049877 │ 2938.91     │ 135.031 │ 0.472441 │\n",
       "│ 5   │ 2     │ 3     │ 0.00035944 │ 2935.77     │ 134.317 │ 0.468254 │\n",
       "│ 6   │ 2     │ 2     │ 4.64e-5    │ 2924.19     │ 133.504 │ 0.449612 │\n",
       "\n",
       "│ Row │ firm_weight │ firm_hp │ firm_ac  │ LHS      │\n",
       "├─────┼─────────────┼─────────┼──────────┼──────────┤\n",
       "│ 1   │ 3071.03     │ 141.529 │ 0.558824 │ -7.46288 │\n",
       "│ 2   │ 2805.63     │ 117.375 │ 0.625    │ -8.58159 │\n",
       "│ 3   │ 2856.27     │ 114.667 │ 0.133333 │ -7.23853 │\n",
       "│ 4   │ 2402.67     │ 86.3333 │ 0.0      │ -7.5124  │\n",
       "│ 5   │ 2721.25     │ 115.0   │ 0.25     │ -7.83999 │\n",
       "│ 6   │ 3022.0      │ 150.0   │ 1.0      │ -9.88724 │"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GMM Estimation\n",
    "I estimate $\\hat{\\theta}$ using the following GMM procedure:\n",
    "$$\\max_\\theta Q_n\\big(\\theta \\big)$$\n",
    "where $Q_n\\big(\\theta\\big) = -\\frac{1}{2}g_n\\big(\\theta\\big)'\\,\\hat{W}\\,g_n\\big(\\theta\\big)$ and $g_n\\big(\\theta\\big) = \\frac{1}{n}\\sum_{r=1}^R g\\big(w_r; \\theta\\big)$. \n",
    "\n",
    "$g\\big(w_r; \\theta\\big) = z_r \\cdot (y_r - x_r \\cdot \\theta)$ is the residual $\\xi_{jt}$ from the model above times the instruments calculated using $w_r$, a row of data.\n",
    "\n",
    "The efficient GMM is estimated with weighting matrix $\\hat{W}_A=\\left(\\frac{1}{n} \\sum_{o=1}^n{\\Big(g(w_o,\\theta_{first})-g_n(w,\\theta_{first})\\Big) \\cdot \\Big(g(w_o,\\theta_{first}) - g_n(w,\\theta_{first})\\Big)'}\\right)^{-1}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "What (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# w is data, with the left-hand-side as its first column, z are included regressors and excluded instruments\n",
    "function gn(w, z, θ)\n",
    "\n",
    "    1/size(w)[1] .* z' * (w[:,1] - w[:, 2:end] * θ)\n",
    "    \n",
    "end\n",
    "\n",
    "#Wrapper creates a closure around the provided data set \n",
    "function Qn_wrapper(w, z)\n",
    "    return θ -> 1/2 * (gn(w,z,θ)' * gn(w,z,θ))[1,1]\n",
    "end\n",
    "\n",
    "function Qn_wrapper(w, z, W)\n",
    "    return θ -> 1/2 * (gn(w,z,θ)' * W * gn(w,z,θ))[1,1]\n",
    "end\n",
    "\n",
    "\n",
    "function g(w, z, θ)\n",
    "    z * (w[1] - w[2:end]' * θ)\n",
    "end\n",
    "\n",
    "function What(w, z, θ)\n",
    "    result = zeros(Float64, size(z)[2], size(z)[2])\n",
    "    gN = gn(w, z, θ)\n",
    "    for i in 1:size(w)[1]\n",
    "        result .+= (g(w[i,:],z[i,:],θ) -gN) * (g(w[i,:],z[i,:],θ) - gN)'\n",
    "    end\n",
    "    return inv(result/size(z)[1])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code iterates over the three years and calculates the efficient GMM using BFGS and forward auto-differentiation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mMethodError: no method matching optimize(::NLSolversBase.OnceDifferentiable{Float64,Array{Float64,1}}, ::Array{Float64,1}, ::Optim.BFGS{LineSearches.HagerZhang{Float64},Optim.##56#58})\u001b[0m\nClosest candidates are:\n  optimize(\u001b[91m::NLopt.Opt\u001b[39m, ::AbstractArray{T<:Real,1}) where T<:Real at /home/juser/.julia/v0.6/NLopt/src/NLopt.jl:532\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mMethodError: no method matching optimize(::NLSolversBase.OnceDifferentiable{Float64,Array{Float64,1}}, ::Array{Float64,1}, ::Optim.BFGS{LineSearches.HagerZhang{Float64},Optim.##56#58})\u001b[0m\nClosest candidates are:\n  optimize(\u001b[91m::NLopt.Opt\u001b[39m, ::AbstractArray{T<:Real,1}) where T<:Real at /home/juser/.julia/v0.6/NLopt/src/NLopt.jl:532\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1m(::##33#35)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Int64\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./In[16]:11\u001b[22m\u001b[22m",
      " [2] \u001b[1mcollect\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Base.Generator{Array{Int64,1},##33#35}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./array.jl:441\u001b[22m\u001b[22m",
      " [3] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "table3 = DataFrame()\n",
    "table3[:year] = [1990, 1991, 1992]\n",
    "\n",
    "table3 = hcat(table3, convert(DataFrame, hcat(\n",
    "    [begin\n",
    "        w = convert(Array{Float64}, data[data[:year] .== year, [:LHS, :weight, :hp, :ac, :price]])\n",
    "        z = convert(Array{Float64}, data[data[:year] .== year, [:weight, :hp, :ac, :comp_weight, :comp_hp, :comp_ac, \n",
    "                                                                                   :firm_weight, :firm_hp, :firm_ac]])\n",
    "        Qn = Qn_wrapper(w, z)\n",
    "\n",
    "        optres = optimize(OnceDifferentiable(Qn, zeros(4); autodiff = :forward), zeros(4), BFGS())\n",
    "        θfirst = optres.minimizer\n",
    "\n",
    "        Qn = Qn_wrapper(w, z, What(w, z, θfirst))\n",
    "        optres = optimize(OnceDifferentiable(Qn, θfirst; autodiff = :forward), θfirst, BFGS())\n",
    "        round.(optres.minimizer, 3)\n",
    "    end for year in [1990, 1991, 1992]]...)')\n",
    ")\n",
    "\n",
    "rename!(table3, names(table3)[2:end], [:βw, :βhp, :βac, :α])\n",
    "table3[:α] = - table3[:α]\n",
    "\n",
    "table3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4\n",
    "The negative $\\alpha$ values are very implausible!\n",
    "Cross-price elasticities are constant over all goods, which is rather unrealistic. For example, increasing the price of a Aston Martin DB11 would shift market share equally to the Ford Prius and the Ferrari 911. \n",
    "\n",
    "Similarily, the own-price elasticity is constant, but in reality some cars will have higher and some lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Nested Logit\n",
    "### 5\n",
    "Using Berry (1994) notation:\n",
    "\n",
    "$$\\log s_{jt} - \\log s_{0t} = \\frac{\\delta_{jt}^*}{1-\\sigma} - \\sigma \\log{D_g}$$\n",
    "where $D_g=\\sum_{j \\in g} e^{\\delta_{jt}^*/(1-\\sigma)}$. That yields:\n",
    "\n",
    "$$\\log s_{jt} - \\log s_{0t} = x'_{jt}\\beta_t - \\alpha_t p_{jt} + \\sigma \\log s_{j|g} + \\xi_{jt}  $$\n",
    "### 6\n",
    "Let me calculate the within group shares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nest_structure in [:nest3, :nest4]\n",
    "    # initialize a column of zeros\n",
    "    data[Symbol(string(\"share_\", string(nest_structure)))] = zeros(size(data)[1])\n",
    "\n",
    "    for y in [1990, 1991, 1992]\n",
    "        for nest in 1:maximum(data[nest_structure])\n",
    "            data[(data[:year] .== y) .* (data[nest_structure] .== nest), Symbol(string(\"share_\", string(nest_structure)))] = \n",
    "                log(data[(data[:year] .== y) .* (data[nest_structure] .== nest), :share]) - \n",
    "                log(sum(data[(data[:year] .== y) .* (data[nest_structure] .== nest), :share]))\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the within group competitor's characteristics (no matter the producing firm), which are being used as an instrument for the within shares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nest_competitor_mean_characteristic (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function nest_competitor_mean_characteristic(good, char::Symbol, nest_structure::Symbol)\n",
    "    mean(data[(data[nest_structure] .== good[nest_structure]) .* (data[:year] .== good[:year]) .* \n",
    "            (data[:car] .!= good[:car]), char]) #same year, same nest, different car\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nest_structure in [:nest3, :nest4]\n",
    "\n",
    "    data[Symbol(string(\"comp_weight_\", string(nest_structure)))] = \n",
    "        [nest_competitor_mean_characteristic(good, :weight, nest_structure) for good in eachrow(data)]\n",
    "\n",
    "    data[Symbol(string(\"comp_hp_\", string(nest_structure)))] = \n",
    "        [nest_competitor_mean_characteristic(good, :hp, nest_structure) for good in eachrow(data)]\n",
    "\n",
    "    data[Symbol(string(\"comp_ac_\", string(nest_structure)))] = \n",
    "        [nest_competitor_mean_characteristic(good, :ac, nest_structure) for good in eachrow(data)];\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>car</th><th>year</th><th>firm</th><th>price</th><th>quantity</th><th>weight</th><th>hp</th><th>ac</th><th>nest3</th><th>nest4</th><th>share</th><th>comp_weight</th><th>comp_hp</th><th>comp_ac</th><th>firm_weight</th><th>firm_hp</th><th>firm_ac</th><th>LHS</th><th>share_nest3</th><th>share_nest4</th><th>comp_weight_nest3</th><th>comp_hp_nest3</th><th>comp_ac_nest3</th><th>comp_weight_nest4</th><th>comp_hp_nest4</th><th>comp_ac_nest4</th></tr></thead><tbody><tr><th>1</th><td>91</td><td>1990</td><td>19</td><td>0.2970233932704021</td><td>52409.0</td><td>0.5559956020578457</td><td>0.4081228050300215</td><td>0</td><td>1</td><td>1</td><td>0.00052409</td><td>2884.78125</td><td>131.59375</td><td>0.4270833333333333</td><td>3071.029411764706</td><td>141.52941176470588</td><td>0.5588235294117647</td><td>-7.462877776838659</td><td>-4.304576788942753</td><td>-3.684711188040598</td><td>0.9528997625875185</td><td>0.7518815787529369</td><td>0.2608695652173913</td><td>0.9115978224718131</td><td>0.6863883539141272</td><td>0.11538461538461539</td></tr><tr><th>2</th><td>35</td><td>1990</td><td>7</td><td>0.4307953969117842</td><td>17122.0</td><td>0.7619198991163071</td><td>0.7420414636909483</td><td>0</td><td>2</td><td>2</td><td>0.00017122</td><td>2936.9590163934427</td><td>134.9262295081967</td><td>0.45081967213114754</td><td>2805.625</td><td>117.375</td><td>0.625</td><td>-8.581591922822227</td><td>-5.573016845671248</td><td>-5.7614217762818</td><td>1.009372262748225</td><td>1.027351029368062</td><td>0.4927536231884058</td><td>0.9905522864668314</td><td>0.927348530582537</td><td>0.4246575342465753</td></tr><tr><th>3</th><td>61</td><td>1990</td><td>16</td><td>0.43822717489186097</td><td>65590.0</td><td>0.8974867280131275</td><td>0.6900985612325818</td><td>0</td><td>1</td><td>1</td><td>0.0006559</td><td>2934.913043478261</td><td>136.40869565217392</td><td>0.5043478260869565</td><td>2856.266666666667</td><td>114.66666666666667</td><td>0.13333333333333333</td><td>-7.238532863836876</td><td>-4.08023187594097</td><td>-3.460366275038815</td><td>0.9454760424580558</td><td>0.7457516710094029</td><td>0.2608695652173913</td><td>0.89846354839661</td><td>0.6755431325217209</td><td>0.11538461538461539</td></tr><tr><th>4</th><td>52</td><td>1990</td><td>10</td><td>0.5360293731096715</td><td>49877.0</td><td>0.8662548762925941</td><td>0.6826781465956724</td><td>0</td><td>1</td><td>1</td><td>0.00049877</td><td>2938.9133858267714</td><td>135.03149606299212</td><td>0.47244094488188976</td><td>2402.6666666666665</td><td>86.33333333333333</td><td>0.0</td><td>-7.51239613448586</td><td>-4.354095146589954</td><td>-3.7342295456877985</td><td>0.9461549957563283</td><td>0.7459129843710749</td><td>0.2608695652173913</td><td>0.8996647734627844</td><td>0.675828533084679</td><td>0.11538461538461539</td></tr><tr><th>5</th><td>26</td><td>1990</td><td>4</td><td>0.6837235741670641</td><td>35944.0</td><td>0.7488780269692712</td><td>0.8607680978814999</td><td>0</td><td>2</td><td>3</td><td>0.00035944</td><td>2935.7698412698414</td><td>134.31746031746033</td><td>0.46825396825396826</td><td>2721.25</td><td>115.0</td><td>0.25</td><td>-7.839993937374661</td><td>-4.831418860223682</td><td>-3.3802007968344165</td><td>1.0095612753880372</td><td>1.025630353510228</td><td>0.4927536231884058</td><td>1.1384493562225968</td><td>1.3454560903014512</td><td>0.8636363636363636</td></tr><tr><th>6</th><td>54</td><td>1990</td><td>11</td><td>0.8420204451426995</td><td>4640.0</td><td>0.9376419659395274</td><td>0.9498130735244137</td><td>1</td><td>2</td><td>2</td><td>4.64e-5</td><td>2924.186046511628</td><td>133.50387596899225</td><td>0.4496124031007752</td><td>3022.0</td><td>150.0</td><td>1.0</td><td>-9.887241742904356</td><td>-6.878666665753377</td><td>-7.067071596363929</td><td>1.0068255661275984</td><td>1.0243398466168523</td><td>0.4782608695652174</td><td>0.9881451348665133</td><td>0.924502344146462</td><td>0.410958904109589</td></tr></tbody></table>"
      ],
      "text/plain": [
       "6×26 DataFrames.DataFrame\n",
       "│ Row │ car │ year │ firm │ price    │ quantity │ weight   │ hp       │ ac │\n",
       "├─────┼─────┼──────┼──────┼──────────┼──────────┼──────────┼──────────┼────┤\n",
       "│ 1   │ 91  │ 1990 │ 19   │ 0.297023 │ 52409.0  │ 0.555996 │ 0.408123 │ 0  │\n",
       "│ 2   │ 35  │ 1990 │ 7    │ 0.430795 │ 17122.0  │ 0.76192  │ 0.742041 │ 0  │\n",
       "│ 3   │ 61  │ 1990 │ 16   │ 0.438227 │ 65590.0  │ 0.897487 │ 0.690099 │ 0  │\n",
       "│ 4   │ 52  │ 1990 │ 10   │ 0.536029 │ 49877.0  │ 0.866255 │ 0.682678 │ 0  │\n",
       "│ 5   │ 26  │ 1990 │ 4    │ 0.683724 │ 35944.0  │ 0.748878 │ 0.860768 │ 0  │\n",
       "│ 6   │ 54  │ 1990 │ 11   │ 0.84202  │ 4640.0   │ 0.937642 │ 0.949813 │ 1  │\n",
       "\n",
       "│ Row │ nest3 │ nest4 │ share      │ comp_weight │ comp_hp │ comp_ac  │\n",
       "├─────┼───────┼───────┼────────────┼─────────────┼─────────┼──────────┤\n",
       "│ 1   │ 1     │ 1     │ 0.00052409 │ 2884.78     │ 131.594 │ 0.427083 │\n",
       "│ 2   │ 2     │ 2     │ 0.00017122 │ 2936.96     │ 134.926 │ 0.45082  │\n",
       "│ 3   │ 1     │ 1     │ 0.0006559  │ 2934.91     │ 136.409 │ 0.504348 │\n",
       "│ 4   │ 1     │ 1     │ 0.00049877 │ 2938.91     │ 135.031 │ 0.472441 │\n",
       "│ 5   │ 2     │ 3     │ 0.00035944 │ 2935.77     │ 134.317 │ 0.468254 │\n",
       "│ 6   │ 2     │ 2     │ 4.64e-5    │ 2924.19     │ 133.504 │ 0.449612 │\n",
       "\n",
       "│ Row │ firm_weight │ firm_hp │ firm_ac  │ LHS      │ share_nest3 │\n",
       "├─────┼─────────────┼─────────┼──────────┼──────────┼─────────────┤\n",
       "│ 1   │ 3071.03     │ 141.529 │ 0.558824 │ -7.46288 │ -4.30458    │\n",
       "│ 2   │ 2805.63     │ 117.375 │ 0.625    │ -8.58159 │ -5.57302    │\n",
       "│ 3   │ 2856.27     │ 114.667 │ 0.133333 │ -7.23853 │ -4.08023    │\n",
       "│ 4   │ 2402.67     │ 86.3333 │ 0.0      │ -7.5124  │ -4.3541     │\n",
       "│ 5   │ 2721.25     │ 115.0   │ 0.25     │ -7.83999 │ -4.83142    │\n",
       "│ 6   │ 3022.0      │ 150.0   │ 1.0      │ -9.88724 │ -6.87867    │\n",
       "\n",
       "│ Row │ share_nest4 │ comp_weight_nest3 │ comp_hp_nest3 │ comp_ac_nest3 │\n",
       "├─────┼─────────────┼───────────────────┼───────────────┼───────────────┤\n",
       "│ 1   │ -3.68471    │ 0.9529            │ 0.751882      │ 0.26087       │\n",
       "│ 2   │ -5.76142    │ 1.00937           │ 1.02735       │ 0.492754      │\n",
       "│ 3   │ -3.46037    │ 0.945476          │ 0.745752      │ 0.26087       │\n",
       "│ 4   │ -3.73423    │ 0.946155          │ 0.745913      │ 0.26087       │\n",
       "│ 5   │ -3.3802     │ 1.00956           │ 1.02563       │ 0.492754      │\n",
       "│ 6   │ -7.06707    │ 1.00683           │ 1.02434       │ 0.478261      │\n",
       "\n",
       "│ Row │ comp_weight_nest4 │ comp_hp_nest4 │ comp_ac_nest4 │\n",
       "├─────┼───────────────────┼───────────────┼───────────────┤\n",
       "│ 1   │ 0.911598          │ 0.686388      │ 0.115385      │\n",
       "│ 2   │ 0.990552          │ 0.927349      │ 0.424658      │\n",
       "│ 3   │ 0.898464          │ 0.675543      │ 0.115385      │\n",
       "│ 4   │ 0.899665          │ 0.675829      │ 0.115385      │\n",
       "│ 5   │ 1.13845           │ 1.34546       │ 0.863636      │\n",
       "│ 6   │ 0.988145          │ 0.924502      │ 0.410959      │"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.a.\n",
    "I calculate the 2SLS and use it as the initial value for the efficient GMM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mMethodError: no method matching optimize(::NLSolversBase.OnceDifferentiable{Float64,Array{Float64,1}}, ::Array{Float64,1}, ::Optim.BFGS{LineSearches.HagerZhang{Float64},Optim.##56#58})\u001b[0m\nClosest candidates are:\n  optimize(\u001b[91m::NLopt.Opt\u001b[39m, ::AbstractArray{T<:Real,1}) where T<:Real at /home/juser/.julia/v0.6/NLopt/src/NLopt.jl:532\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mMethodError: no method matching optimize(::NLSolversBase.OnceDifferentiable{Float64,Array{Float64,1}}, ::Array{Float64,1}, ::Optim.BFGS{LineSearches.HagerZhang{Float64},Optim.##56#58})\u001b[0m\nClosest candidates are:\n  optimize(\u001b[91m::NLopt.Opt\u001b[39m, ::AbstractArray{T<:Real,1}) where T<:Real at /home/juser/.julia/v0.6/NLopt/src/NLopt.jl:532\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1m(::##52#55{Symbol})\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Int64\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./In[21]:26\u001b[22m\u001b[22m",
      " [2] \u001b[1mnext\u001b[22m\u001b[22m at \u001b[1m./iterators.jl:708\u001b[22m\u001b[22m [inlined]",
      " [3] \u001b[1mgrow_to!\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Union{},1}, ::Base.Iterators.Flatten{Base.Generator{Array{Symbol,1},##51#54}}, ::Tuple{Int64,Base.Generator{Array{Int64,1},##52#55{Symbol}},Int64}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./array.jl:498\u001b[22m\u001b[22m",
      " [4] \u001b[1mgrow_to!\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Base.Iterators.Flatten{Base.Generator{Array{Symbol,1},##51#54}}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./array.jl:491\u001b[22m\u001b[22m",
      " [5] \u001b[1mcollect\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Base.Iterators.Flatten{Base.Generator{Array{Symbol,1},##51#54}}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./array.jl:397\u001b[22m\u001b[22m",
      " [6] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "table6 = DataFrame()\n",
    "table6[:year] = [1990, 1991, 1992, 1990, 1991, 1992]\n",
    "table6[:nesting] = [3, 3, 3, 4, 4, 4]\n",
    "\n",
    "table6 = hcat(table6, convert(DataFrame, hcat(\n",
    "    [begin\n",
    "        # do 2SLS:\n",
    "        X = convert(Array{Float64}, data[data[:year] .== year, \n",
    "                [:weight, :hp, :ac, :price, Symbol(string(\"share_\", string(nest_structure)))]])\n",
    "                    \n",
    "        Z = convert(Array{Float64}, data[data[:year] .== year, \n",
    "                [:weight, :hp, :ac, :comp_weight, :comp_hp, :comp_ac, :firm_weight, :firm_hp, :firm_ac, \n",
    "                Symbol(string(\"comp_weight_\", string(nest_structure))), \n",
    "                Symbol(string(\"comp_hp_\", string(nest_structure))), \n",
    "                Symbol(string(\"comp_ac_\", string(nest_structure)))]])\n",
    "\n",
    "        y = convert(Array{Float64}, data[data[:year] .== year, [:LHS]])\n",
    "\n",
    "        θ2SLS = ((X'Z * (Z'Z)^(-1) * Z'X) \\ (X'Z * (Z'Z)^(-1) * Z'y))[:,1]\n",
    "\n",
    "        # do efficient GMM starting from 2SLS:\n",
    "        w = hcat(data[data[:year] .== year, :LHS], X)\n",
    "        z = Z\n",
    "\n",
    "        Qn = Qn_wrapper(w, z)\n",
    "        optres = optimize(OnceDifferentiable(Qn, θ2SLS; autodiff = :forward), θ2SLS, BFGS())\n",
    "        θfirst = optres.minimizer\n",
    "\n",
    "        Qn = Qn_wrapper(w, z, What(w, z, θfirst))\n",
    "        optres = optimize(OnceDifferentiable(Qn, θfirst; autodiff = :forward), θfirst, BFGS(), Optim.Options(g_tol=1e-10))\n",
    "        round.(optres.minimizer, 3)\n",
    "                    \n",
    "    end for nest_structure in [:nest3, :nest4] for year in [1990, 1991, 1992]] ...)')\n",
    ")\n",
    "\n",
    "rename!(table6, names(table6)[2:end], [:nest, :βw, :βhp, :βac, :α, :σ])\n",
    "table6[:α] = - table6[:α]\n",
    "\n",
    "table6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimates for the price coefficients are more positive and more plausible, except those in nest 4!\n",
    "\n",
    "#### 6.b.\n",
    "The conditional error must be time-independent. This is very implausible with real data, since brands have autocorrelation in how much they are liked by buyers.\n",
    "\n",
    "#### 6.c.\n",
    "$\\sigma$ is often close to one, but in 1991 the two nesting structures give very different estimates for $\\sigma$. With 4 nests the $\\sigma=0.972$ indicates there is much correlation within the nest. The $\\sigma$ values greater than one might not be consistent with random utility maximization.\n",
    "#### 6.d.\n",
    "The $\\alpha$ also varies a lot over the three years! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7\n",
    "#### 7.a.\n",
    "Lets have a look at price elasticities in the logit and the nested logit model:\n",
    "\n",
    "|          |   Standard Logit Elasticities   | Nested Logit Elasticities |\n",
    "|:---:|:---:|:---:|\n",
    "| $\\frac{\\partial s_{jt}}{\\partial p_{jt}}$  | $-\\alpha s_{jt}\\big(1-s_{jt}\\big)$  | $-\\alpha s_{jt}\\big(\\frac{1}{1-\\sigma}-\\frac{\\sigma}{1-\\sigma}s_{jt|g}-s_{jt}\\big)$  |\n",
    "|  $\\frac{\\partial s_{jt}}{\\partial p_{kt}}$ | $\\alpha s_{jt}s_{kt}$  | $\\quad\\quad\\begin{cases}\n",
    "\\alpha s_{kt}\\big(\\frac{\\sigma}{1-\\sigma}s_{jt|g}+s_{jt}\\big) & \\text{same}\\\\\n",
    "\\alpha s_{jt}s_{kt} & \\text{different}\n",
    "\\end{cases}$  |\n",
    "\n",
    "The nested logit allows for a more flexible substitution pattern!\n",
    "#### 7.b.\n",
    "One could grow a dicision tree (or use some other machine learning methods, \"nearest neighbor\", etc.) to flexibly use the existing data (characteristics only, no market shares) to create nests. As validation I would check whether the catagories resemble something like: hypercar/supercar, sports car, SUV, hatchback, ...\n",
    "#### 7.c.\n",
    "We need to define the nesting structure a priori and must not make any mistakes. It is clear that we would need multiple layers of nesting to get a realistic classification, but then it is hard to justify why to split first according to one criterium instead of another.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8\n",
    "#### 8.a.\n",
    "Probit would allow for a very flexible substitution pattern, but with more than 120 cars per year the covariance matrix would get very big!\n",
    "#### 8.b.\n",
    "The pure characteristics model could not reflect the (unobserved) emotional value of people buying an Alfa Romeo Giulia Quadrifoglio although it is a bad car for the price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C: Mixed Logit\n",
    "### 9\n",
    "#### 9.a.\n",
    "Now:\n",
    "$$u_{ijt} = x'_{jt}\\beta_t - \\alpha_{i} p_{jt}+ \\xi_{jt} + \\epsilon_{ijt} \\quad \\forall t \\in T$$\n",
    "where $\\alpha_i=\\frac{1}{y_i}$ and $y_i \\sim \\mathcal{LN}$, the log-normal distribution.\n",
    "\n",
    "In BLP (1995) the $\\beta$ is normally distributed and the $\\delta_j = x_j' \\cdot \\mu_\\beta - \\alpha \\cdot p_j + \\xi_j$ the rest $x_j' \\cdot \\Sigma_\\beta \\cdot \\nu$ is integrated out.\n",
    "\n",
    "Compared to BLP (1995) this is different in the sense the my $\\delta_{jt}$ is now $x'_{jt}\\beta_t -$ <font color='red'>$\\mu_\\alpha$</font>\n",
    "$p_{jt} + \\xi_{jt}$, the $\\alpha$ is integrated out and its distributional parameters are estimated. More precisely I estimate $\\theta=\\Big[\\beta_w, \\beta_{hp}, \\beta_{ac}, \\mu_y, \\sigma_y\\Big]$, where the latter two are such that $\\log y_i \\sim \\mathcal{N}(\\mu_y, \\sigma_y)$, and recover the moments for $\\alpha$.\n",
    "\n",
    "The mixed logit shares are in this setting:\n",
    "$$s_{jt}=\\int_{0}^{\\infty}\\frac{exp\\big(x'_{jt}\\beta_{t}-(\\mu_{\\alpha}-\\mu_{\\alpha}+\\frac{1}{y_{i}})p_{jt}+\\xi_{jt}\\big)}{1+\\sum_{k}exp\\big(x'_{jt}\\beta_{t}-\\frac{1}{y_{i}}p_{jt}+\\xi_{jt}\\big)}\\frac{1}{y_{i}\\sigma_{y}\\sqrt{2\\pi}}\\exp\\Big(-\\frac{(\\log y_{i}-\\mu_{y})^{2}}{2\\sigma_{y}^{2}}\\Big)dy_{i}=\n",
    "$$\n",
    "\n",
    "$$\\int_{0}^{\\infty}\\frac{exp\\big(\\delta_{jt}+(\\mu_{\\alpha}-\\frac{1}{y_{i}})p_{jt}\\big)}{1+\\sum_{k}exp\\big(\\delta_{kt}+(\\mu_{\\alpha}-\\frac{1}{y_{i}})p_{kt}\\big)}\\frac{1}{y_{i}\\sigma_{y}\\sqrt{2\\pi}}\\exp\\Big(-\\frac{(\\log y_{i}-\\mu_{y})^{2}}{2\\sigma_{y}^{2}}\\Big)dy_{i}=\n",
    "$$\n",
    "\n",
    "Changing the integration variable:\n",
    "\n",
    "$$\\int_{-\\infty}^{\\infty}\\frac{exp\\big(\\delta_{jt}+(\\mu_{\\alpha}-\\frac{1}{\\exp(e_{i})})p_{jt}\\big)}{1+\\sum_{k}exp\\big(\\delta_{kt}+(\\mu_{\\alpha}-\\frac{1}{\\exp(e_{i})})p_{kt}\\big)}\\frac{1}{\\exp(e_{i})\\sigma_{y}\\sqrt{2\\pi}}\\exp\\Big(-\\frac{(e_{i}-\\mu_{y})^{2}}{2\\sigma_{y}^{2}}\\Big)\\exp(e_{i})de_{i}=\n",
    "$$\n",
    "\n",
    "$$\\int_{-\\infty}^{\\infty}\\frac{exp\\Big(\\delta_{jt}+(\\mu_{\\alpha}-\\exp(-e_{i}))p_{jt}\\Big)}{1+\\sum_{k}exp\\Big(\\delta_{kt}+(\\mu_{\\alpha}-\\exp(-e_{i}))p_{kt}\\Big)}\\frac{1}{\\sigma_{y}\\sqrt{2\\pi}}\\exp\\Big(-\\frac{(e_{i}-\\mu_{y})^{2}}{2\\sigma_{y}^{2}}\\Big)de_{i}=\n",
    "$$\n",
    "\n",
    "Again changing the integration variable to standardize the normal distribution (I recycle the $e_i$) and plugging-in for $\\mu_\\alpha = \\exp(-\\mu_{y}+\\frac{1}{2}\\sigma_{y}^{2})$\n",
    "\n",
    "$$\\int_{-\\infty}^{\\infty}\\underset{h(e_{i};\\delta_{jt},\\,p_{jt})}{\\underbrace{\\frac{1}{\\sqrt{\\pi}}\\frac{exp\\Big(\\delta_{jt}+\\Big(\\exp(-\\mu_{y}+\\frac{1}{2}\\sigma_{y}^{2})-\\exp(-\\mu_{y}-\\sqrt{2}\\sigma_{y}e_{i})\\Big)\\,p_{jt}\\Big)}{1+\\sum_{k}exp\\Big(\\delta_{kt}+\\Big(\\exp(-\\mu_{y}+\\frac{1}{2}\\sigma_{y}^{2})-\\exp(-\\mu_{y}-\\sqrt{2}\\sigma_{y}e_{i})\\Big)\\,p_{kt}\\Big)}}}\\phi(e_{i})de_{i}\\approx\n",
    "$$\n",
    "\n",
    "$$\\approx\\sum_{l=1}^n q_l \\, h\\Big(e_{l};\\delta_{jt},\\,p_{jt}\\Big)$$\n",
    "where $q_l$ and $e_l$ are the Gauss-Hermite weights and points.\n",
    "\n",
    "The moment function is now: $g\\big(w_r; \\theta\\big) = z_r \\cdot (\\delta_r - x_r \\cdot \\beta + \\mu_\\alpha \\cdot p_r)$ where the $\\delta_r$ comes from the solution to the BLP iteration: \n",
    "\n",
    "$$\\delta^{(k)}(\\theta) = \\delta^{(k-1)}(\\theta) + \\log(\\tilde{s}_j) - \\log\\Big(s_j(\\delta^{(k-1)}, \\theta)\\Big)$$\n",
    "Those $\\delta$ values are then consistent with the observed market shares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qn_wrapper_BLP (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using FastGaussQuadrature\n",
    "\n",
    "function gn_BLP(w, z, θ)\n",
    "    1/size(w)[1] .* z' * (w[:,1] .- w[:, 2:4] * θ[1:3] .+ θ[4] .* w[:, 5])\n",
    "end\n",
    "\n",
    "#Wrapper creates a closure around the provided data set \n",
    "function Qn_wrapper_BLP(w, z)\n",
    "    \n",
    "    δ = zeros(size(w)[1])\n",
    "    (e, q) = gausshermite(30)\n",
    "    p = w[:, 5] #price\n",
    "    s = w[:, 1] #share\n",
    "    \n",
    "    \n",
    "    return θ -> begin #w, hp, ac, mu, sigma\n",
    "        μ_y = θ[4]\n",
    "        σ_y = θ[5]\n",
    "        \n",
    "        h(e) = 1/(√π) .* exp.(δ .+ (exp(-μ_y + 1/2 * σ_y^2) - exp(-μ_y - (√2) * σ_y * e)) .* p) / \n",
    "            (1 + sum(exp.(δ .+ (exp(-μ_y + 1/2 * σ_y^2) - exp(-μ_y - (√2) * σ_y * e)) .* p)))\n",
    "        \n",
    "        error = 1\n",
    "        δ = zeros(size(w)[1])\n",
    "        \n",
    "        while error > 1e-14\n",
    "            δold = copy(δ)\n",
    "            δ = δold .+ log.(s) .- log.(hcat(h.(e)...) * q)\n",
    "            error = maximum(abs.(δ - δold))\n",
    "        end\n",
    "\n",
    "        gvec = gn_BLP(hcat(δ, w[:, 2:5]), z, θ) \n",
    "        1/2 * (gvec' * gvec)[1,1]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Results of Optimization Algorithm\n",
       " * Algorithm: Nelder-Mead\n",
       " * Starting Point: [0.0,0.0,0.0,0.0,1.0]\n",
       " * Minimizer: [-4.749505571934413,-5.579010506165104, ...]\n",
       " * Minimum: 5.322820e+03\n",
       " * Iterations: 1000\n",
       " * Convergence: false\n",
       "   *  √(Σ(yᵢ-ȳ)²)/n < 1.0e-08: false\n",
       "   * Reached Maximum Number of Iterations: true\n",
       " * Objective Calls: 1652"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = 1990\n",
    "\n",
    "w = convert(Array{Float64}, data[data[:year] .== year, [:share, :weight, :hp, :ac, :price]])\n",
    "z = convert(Array{Float64}, data[data[:year] .== year, [:weight, :hp, :ac, :comp_weight, :comp_hp, :comp_ac,\n",
    "                                                                           :firm_weight, :firm_hp, :firm_ac]])\n",
    "\n",
    "Qn = Qn_wrapper_BLP(w, z)\n",
    "\n",
    "optres = optimize(Qn, vcat(zeros(4), 1), NelderMead(), Optim.Options(iterations=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       " -4.74951\n",
       " -5.57901\n",
       "  6.43767\n",
       " 10.367  \n",
       "  5.03017"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optres.minimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optres = optimize(Qn, optres.minimizer, NelderMead(), Optim.Options(iterations=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       " -4.88626  \n",
       " -6.54686  \n",
       "  9.21254  \n",
       "  0.801829 \n",
       "  0.0602673"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "θ = optres.minimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence $\\mu_\\alpha$ is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44932328967708257"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp(-θ[4] + 1/2 * θ[5]^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it is very positive, which is good. Car buyers dislike prices!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a mess, let me try Dube Fox Su (2009):\n",
    "$$s_{jt}=\\int_{0}^{\\infty}\\frac{exp\\big(x'_{jt}\\beta_{t}-\\frac{1}{y_{i}}p_{jt}+\\xi_{jt}\\big)}{1+\\sum_{k}exp\\big(x'_{jt}\\beta_{t}-\\frac{1}{y_{i}}p_{jt}+\\xi_{jt}\\big)}\\frac{1}{y_{i}\\sigma_{y}\\sqrt{2\\pi}}\\exp\\Big(-\\frac{(\\log y_{i}-\\mu_{y})^{2}}{2\\sigma_{y}^{2}}\\Big)dy_{i}=\n",
    "$$\n",
    "$$s_{jt}=\\int_{-\\infty}^{\\infty}\\frac{exp\\big(x'_{jt}\\beta_{t}-\\frac{1}{\\exp e_{i}}p_{jt}+\\xi_{jt}\\big)}{1+\\sum_{k}exp\\big(x'_{jt}\\beta_{t}-\\frac{1}{\\exp e_{i}}p_{jt}+\\xi_{jt}\\big)}\\frac{1}{\\sigma_{y}\\sqrt{2\\pi}}\\exp\\Big(-\\frac{(e_{i}-\\mu_{y})^{2}}{2\\sigma_{y}^{2}}\\Big)de_{i}=\n",
    "$$\n",
    "$$s_{jt}=\\int_{-\\infty}^{\\infty}\\frac{1}{\\sqrt\\pi}\\frac{exp\\big(x'_{jt}\\beta_{t}-\\exp (-\\mu_{y}-\\sqrt{2}\\sigma_{y}e_{i}) p_{jt}+\\xi_{jt}\\big)}{1+\\sum_{k}exp\\big(x'_{jt}\\beta_{t}-\\exp (-\\mu_{y}-\\sqrt{2}\\sigma_{y}e_{i})p_{jt}+\\xi_{jt}\\big)}\\phi(e_i)de_{i}=\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 1990\n",
    "\n",
    "w = convert(Array{Float64}, data[data[:year] .== year, [:share, :weight, :hp, :ac, :price]])\n",
    "z = convert(Array{Float64}, data[data[:year] .== year, [:weight, :hp, :ac, :comp_weight, :comp_hp, :comp_ac,\n",
    "                                                                      :firm_weight, :firm_hp, :firm_ac]]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mArgumentError: invalid NLopt arguments\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mArgumentError: invalid NLopt arguments\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1mchk\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Int32\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/juser/.julia/v0.6/NLopt/src/NLopt.jl:259\u001b[22m\u001b[22m",
      " [2] \u001b[1mchks\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Int32\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/juser/.julia/v0.6/NLopt/src/NLopt.jl:276\u001b[22m\u001b[22m",
      " [3] \u001b[1moptimize!\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::NLopt.Opt, ::Array{Float64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/juser/.julia/v0.6/NLopt/src/NLopt.jl:529\u001b[22m\u001b[22m",
      " [4] \u001b[1moptimize\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::NLopt.Opt, ::Array{Float64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/juser/.julia/v0.6/NLopt/src/NLopt.jl:532\u001b[22m\u001b[22m",
      " [5] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "using NLopt\n",
    "using ForwardDiff\n",
    "\n",
    "n = 5 + size(w)[1]\n",
    "\n",
    "opt = Opt(:AUGLAG, n)\n",
    "\n",
    "function f(ζ::Vector, grad::Vector)\n",
    "    if length(grad) > 0\n",
    "        grad[:] = 1/(size(ξ)^2) * vcat(zeros(5), 2 .* ζ[6:end]' * z * z')\n",
    "    end\n",
    "        \n",
    "    return (1/size(ξ) .* z' * ζ[6:end])' * (1/size(ξ) .* z' * ζ[6:end])\n",
    "end\n",
    "\n",
    "min_objective!(opt, f)\n",
    "\n",
    "function c(result::Vector, ζ::Vector, grad::Matrix)\n",
    "    \n",
    "    h(e, ζ) = 1/(√π) .* exp.(w[:, 2:4]' * ζ[1:3] .- exp(-ζ[4] -(√2) * ζ[5] * e) * w[:, 5] + ζ[6:end]) / \n",
    "            (1 + sum(exp.(w[:, 2:4]' * ζ[1:3] .- exp(-ζ[4] -(√2) * ζ[5] * e) * w[:, 5] + ζ[6:end])))\n",
    "    \n",
    "    (e, q) = gausshermite(30)\n",
    "    \n",
    "    h_wrapper(e) = return ζ -> -log.(hcat(h(e, ζ)...) * q)\n",
    "    \n",
    "    if length(grad) > 0\n",
    "        ForwardDiff.jacobian(h_wrapper(e))(ζ)\n",
    "    end\n",
    "        \n",
    "    result[:] = log.(w[:, 1]) - log.(hcat(h.(e)...) * q)\n",
    "end\n",
    "\n",
    "equality_constraint!(opt, c, 1e-6 * ones(n))\n",
    "#maxtime!(opt, 60.)\n",
    "\n",
    "optimize(opt, zeros(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f (generic function with 2 methods)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x) = x[1] * x[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.b.\n",
    "$\\alpha_i = \\alpha_1+\\alpha_2/y_i \\implies \\mu_\\alpha = \\alpha_1+\\alpha_2 \\cdot \\exp(-\\mu_{y}+\\frac{1}{2}\\sigma_{y}^{2})$ hence $\\alpha_1$ is not identified, $\\alpha_2$ might be by the variance or higher moments.\n",
    "The moment conditions would be derived by plugging the new $\\mu_\\alpha$ into the integral above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10\n",
    "#### 10.a.\n",
    "With fixed parameters on the distribution of $y_i$ there are only 3 parameters to estimate. \n",
    "$$35000 = \\exp(\\mu_y + \\frac{\\sigma_y^2}{2})$$\n",
    "$$45000^2 = (\\exp(\\sigma_y^2) - 1)\\cdot\\exp(2\\mu_y+\\sigma_y^2)$$\n",
    "Hence:\n",
    "$$2(\\log 35000 - \\mu_y) = \\sigma_y^2$$\n",
    "$$2\\log45000 = \\log(\\exp(\\sigma_y^2) - 1) + 2\\mu_y+\\sigma_y^2$$\n",
    "And:\n",
    "$$\\mu_y = \\log\\Big(\\frac{35000^2}{\\sqrt{45000^2 + 35000^2}}\\Big)$$\n",
    "$$\\sigma_y = \\sqrt{\\log\\Big(1+\\frac{45000^2}{35000^2}\\Big)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qn_wrapper_BLP_fixed (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Wrapper creates a closure around the provided data set \n",
    "function Qn_wrapper_BLP_fixed(w, z)\n",
    "    \n",
    "    δ = zeros(size(w)[1])\n",
    "    (e, q) = gausshermite(30)\n",
    "    p = w[:, 5] #price\n",
    "    s = w[:, 1] #share\n",
    "    \n",
    "    μ_y = log(35000^2 / sqrt(45000^2 + 35000^2))\n",
    "    σ_y = sqrt(log(1+(45000^2)/(35000^2)))\n",
    "    \n",
    "    return θ -> begin #w, hp, ac\n",
    "        push!(θ, μ_y, σ_y)\n",
    "        \n",
    "        h(e) = 1/(√π) .* exp.(δ .+ (exp(-μ_y + 1/2 * σ_y^2) - exp(-μ_y - (√2) * σ_y * e)) .* p) / \n",
    "            (1 + sum(exp.(δ .+ (exp(-μ_y + 1/2 * σ_y^2) - exp(-μ_y - (√2) * σ_y * e)) .* p)))\n",
    "        \n",
    "        error = 1\n",
    "        δ = zeros(size(w)[1])\n",
    "        \n",
    "        while error > 1e-13\n",
    "            δold = copy(δ)\n",
    "            δ = δold .+ log.(s) .- log.(hcat(h.(e)...) * q)\n",
    "            error = maximum(abs.(δ - δold))\n",
    "        end\n",
    "\n",
    "        gvec = gn_BLP(hcat(δ, w[:, 2:5]), z, θ) \n",
    "        1/2 * (gvec' * gvec)[1,1]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mBoundsError\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mBoundsError\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1mcopy!\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Float64,1}, ::Int64, ::Array{Float64,1}, ::Int64, ::Int64\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./array.jl:132\u001b[22m\u001b[22m",
      " [2] \u001b[1mupdate_state!\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::NLSolversBase.NonDifferentiable{Float64}, ::Optim.NelderMeadState{Float64,1}, ::Optim.NelderMead{Optim.AffineSimplexer,Optim.AdaptiveParameters}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/opt/julia_packages/.julia/v0.6/Optim/src/multivariate/solvers/zeroth_order/nelder_mead.jl:171\u001b[22m\u001b[22m",
      " [3] \u001b[1moptimize\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::NLSolversBase.NonDifferentiable{Float64}, ::Array{Float64,1}, ::Optim.NelderMead{Optim.AffineSimplexer,Optim.AdaptiveParameters}, ::Optim.Options{Void}, ::Optim.NelderMeadState{Float64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/opt/julia_packages/.julia/v0.6/Optim/src/multivariate/optimize/optimize.jl:46\u001b[22m\u001b[22m",
      " [4] \u001b[1moptimize\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::NLSolversBase.NonDifferentiable{Float64}, ::Array{Float64,1}, ::Optim.NelderMead{Optim.AffineSimplexer,Optim.AdaptiveParameters}, ::Optim.Options{Void}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/opt/julia_packages/.julia/v0.6/Optim/src/multivariate/optimize/optimize.jl:17\u001b[22m\u001b[22m",
      " [5] \u001b[1moptimize\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Tuple{##58#62{Array{Float64,2},Array{Float64,2},Array{Float64,1},Array{Float64,1},Array{Float64,1},Array{Float64,1},Float64,Float64}}, ::Array{Float64,1}, ::Optim.NelderMead{Optim.AffineSimplexer,Optim.AdaptiveParameters}, ::Optim.Options{Void}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/opt/julia_packages/.julia/v0.6/Optim/src/multivariate/optimize/interface.jl:79\u001b[22m\u001b[22m",
      " [6] \u001b[1moptimize\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Function, ::Array{Float64,1}, ::Optim.NelderMead{Optim.AffineSimplexer,Optim.AdaptiveParameters}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/opt/julia_packages/.julia/v0.6/Optim/src/multivariate/optimize/interface.jl:74\u001b[22m\u001b[22m",
      " [7] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "year = 1990\n",
    "\n",
    "w = convert(Array{Float64}, data[data[:year] .== year, [:share, :weight, :hp, :ac, :price]])\n",
    "z = convert(Array{Float64}, data[data[:year] .== year, [:weight, :hp, :ac, :comp_weight, :comp_hp, :comp_ac,\n",
    "                                                                           :firm_weight, :firm_hp, :firm_ac]])\n",
    "\n",
    "Qn = Qn_wrapper_BLP_fixed(w, z)\n",
    "\n",
    "optres = optimize(Qn, [-9.0869, 0.365007, 1.77367], NelderMead())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
